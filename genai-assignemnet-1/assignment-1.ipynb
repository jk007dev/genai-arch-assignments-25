{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9dad8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import argparse\n",
    "import yfinance as yf\n",
    "import mlflow\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_google_vertexai import ChatVertexAI\n",
    "from langchain_community.retrievers import ExaSearchRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f86162",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field \n",
    "from typing import List, Optional\n",
    "\n",
    "class SentimentProfile(BaseModel):\n",
    "    \"\"\"Structured sentiment profile for a company based on recent news.\"\"\"\n",
    "    company_name: str = Field(description=\"The name of the company being analyzed.\")\n",
    "    stock_code: str = Field(description=\"The stock market ticker symbol for the company.\")\n",
    "    news_summary: str = Field(description=\"A brief, one-paragraph summary of the key news points.\")\n",
    "    sentiment: str = Field(description=\"Overall market sentiment. Must be one of: 'Positive', 'Negative', 'Neutral'.\")\n",
    "    people_names: list[str] = Field(description=\"List of key people mentioned in the news (e.g., CEOs, executives).\")\n",
    "    places_names: list[str] = Field(description=\"List of key geographical locations or places mentioned.\")\n",
    "    other_companies_referred: list[str] = Field(description=\"List of other companies mentioned in the news.\")\n",
    "    related_industries: list[str] = Field(description=\"List of industries related to the news content.\")\n",
    "    market_implications: str = Field(description=\"A brief analysis of the potential market implications of the news.\")\n",
    "    confidence_score: float = Field(description=\"A confidence score (0.0 to 1.0) in the sentiment analysis.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e02033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Component A: Get Stock Code\n",
    "def get_stock_code(company_name: str) -> str:\n",
    "    \"\"\"Fetches the stock ticker for a given company name using yfinance.\"\"\"\n",
    "    with mlflow.start_span(name=\"Stock Code Extraction\") as span:\n",
    "        try:\n",
    "            span.set_inputs({\"company_name\": company_name})\n",
    "            ticker = yf.Ticker(company_name).ticker\n",
    "            if not ticker or ticker == \"-\":\n",
    "                raise ValueError(\"Invalid or not found.\")\n",
    "            span.set_outputs({\"stock_code\": ticker})\n",
    "            print(f\"‚úÖ Found stock code for {company_name}: {ticker}\")\n",
    "            return ticker\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Could not find stock code for {company_name}: {e}\")\n",
    "            span.set_outputs({\"error\": str(e)})\n",
    "            return \"N/A\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac32263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Component B: Fetch Company News\n",
    "def get_company_news(search_query: dict) -> str:\n",
    "    \"\"\"Fetches recent news articles for a company using the Exa search tool.\"\"\"\n",
    "    company_name = search_query.get(\"company\")\n",
    "    stock_code = search_query.get(\"stock_code\")\n",
    "    \n",
    "    with mlflow.start_span(name=\"News Fetching\") as span:\n",
    "        span.set_inputs({\"company_name\": company_name, \"stock_code\": stock_code})\n",
    "        print(f\"üîé Fetching news for {company_name} ({stock_code})...\")\n",
    "        \n",
    "        # Using ExaSearchRetriever from LangChain\n",
    "        retriever = ExaSearchRetriever(k=5, highlights=True)\n",
    "        query = f\"Recent financial news, market performance, and analysis for {company_name} ({stock_code})\"\n",
    "        \n",
    "        try:\n",
    "            docs = retriever.invoke(query)\n",
    "            # Format the retrieved documents into a single context string\n",
    "            context = \"\\n\\n---\\n\\n\".join(\n",
    "                [f\"Article: {doc.page_content}\" for doc in docs]\n",
    "            )\n",
    "            span.set_outputs({\"news_context_length\": len(context), \"num_articles\": len(docs)})\n",
    "            print(f\"‚úÖ Fetched {len(docs)} news articles.\")\n",
    "            return context\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error fetching news: {e}\")\n",
    "            span.set_outputs({\"error\": str(e)})\n",
    "            return \"Could not fetch news.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cce2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Construct the LangChain Chain using LCEL ---\n",
    "\n",
    "def build_sentiment_analyzer_chain():\n",
    "    \"\"\"Builds and returns the full LangChain Expression Language (LCEL) chain.\"\"\"\n",
    "    \n",
    "    # Initialize the LLM (Gemini gemini-2.0-flash-001 via Vertex AI)\n",
    "    llm = ChatVertexAI(\n",
    "        model_name=\"gemini-2.0-flash-001\",\n",
    "        temperature=0.2,\n",
    "        convert_system_message_to_human=True # Ensures system messages are treated as user prompts\n",
    "    )\n",
    "    \n",
    "    # Initialize the Pydantic Output Parser\n",
    "    parser = PydanticOutputParser(pydantic_object=SentimentProfile)\n",
    "\n",
    "    # Define the final prompt template for sentiment analysis\n",
    "    prompt_template = ChatPromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        As a senior financial analyst, your task is to analyze the provided news context about a company and generate a structured sentiment profile in JSON format.\n",
    "        \n",
    "        **Company Name:** {company}\n",
    "        **Stock Code:** {stock_code}\n",
    "\n",
    "        **Recent News Context:**\n",
    "        ---\n",
    "        {news_context}\n",
    "        ---\n",
    "        \n",
    "        Based *only* on the information in the news context provided, perform the following actions:\n",
    "        1.  Determine the overall market sentiment (Positive, Negative, or Neutral).\n",
    "        2.  Summarize the key news points concisely.\n",
    "        3.  Extract all named entities: people, places, and other companies.\n",
    "        4.  Identify related industries.\n",
    "        5.  Analyze potential market implications.\n",
    "        6.  Provide a confidence score for your sentiment analysis.\n",
    "        \n",
    "        {format_instructions}\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    # Use RunnableLambda to wrap our Python functions for use in the chain\n",
    "    get_stock_code_runnable = RunnableLambda(lambda x: get_stock_code(x['company']))\n",
    "    fetch_news_runnable = RunnableLambda(get_company_news)\n",
    "\n",
    "    # Assemble the chain using LCEL\n",
    "    # This architecture allows data to flow and be enriched at each step.\n",
    "    chain = (\n",
    "        RunnablePassthrough.assign(\n",
    "            stock_code=get_stock_code_runnable\n",
    "        )\n",
    "        .assign(\n",
    "            news_context=fetch_news_runnable\n",
    "        )\n",
    "        .assign(\n",
    "            analysis_result=(\n",
    "                lambda x: {\"format_instructions\": parser.get_format_instructions()} |\n",
    "                prompt_template |\n",
    "                llm |\n",
    "                parser\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13cb798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. Main Execution Block ---\n",
    "\n",
    "def main(company_name: str):\n",
    "    \"\"\"Main function to run the sentiment analysis pipeline.\"\"\"\n",
    "    \n",
    "    # Start an MLflow run to log metrics, parameters, and artifacts\n",
    "    with mlflow.start_run() as run:\n",
    "        run_id = run.info.run_id\n",
    "        print(f\"üöÄ Starting MLflow Run ID: {run_id}\")\n",
    "        mlflow.log_param(\"company_name\", company_name)\n",
    "\n",
    "        # Build the chain\n",
    "        analyzer_chain = build_sentiment_analyzer_chain()\n",
    "\n",
    "        # Invoke the chain with the company name\n",
    "        print(f\"\\nüß† Starting sentiment analysis for '{company_name}'...\")\n",
    "        input_data = {\"company\": company_name}\n",
    "        \n",
    "        with mlflow.start_span(name=\"Full Sentiment Analysis Pipeline\") as span:\n",
    "            span.set_inputs(input_data)\n",
    "            result = analyzer_chain.invoke(input_data)\n",
    "            span.set_outputs({\"final_result\": result})\n",
    "\n",
    "        # Extract the final parsed object\n",
    "        sentiment_profile = result.get(\"analysis_result\")\n",
    "        \n",
    "        if sentiment_profile:\n",
    "            print(\"\\n--- ‚úÖ Analysis Complete ---\")\n",
    "            # Convert Pydantic model to a dictionary for logging and printing\n",
    "            output_dict = sentiment_profile.dict()\n",
    "            print(json.dumps(output_dict, indent=2))\n",
    "\n",
    "            # Log the final JSON output as an artifact in MLflow\n",
    "            output_path = f\"sentiment_profile_{company_name.replace(' ', '_')}.json\"\n",
    "            with open(output_path, \"w\") as f:\n",
    "                json.dump(output_dict, f, indent=2)\n",
    "            mlflow.log_artifact(output_path)\n",
    "            print(f\"\\nüìÑ Saved and logged output to '{output_path}'\")\n",
    "        else:\n",
    "            print(\"\\n--- ‚ùå Analysis Failed ---\")\n",
    "            mlflow.log_param(\"status\", \"Failed\")\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description=\"Real-Time Market Sentiment Analyzer\")\n",
    "    parser.add_argument(\n",
    "        \"-c\", \"--company\", \n",
    "        type=str, \n",
    "        required=True, \n",
    "        help=\"The name of the company to analyze (e.g., 'Google', 'Microsoft').\"\n",
    "    )\n",
    "    args = parser.parse_args()\n",
    "    main(args.company)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
